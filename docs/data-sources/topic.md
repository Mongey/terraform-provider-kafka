---
page_title: "kafka_topic Data Source - terraform-provider-kafka"
subcategory: ""
description: |-
  Retrieves information about an existing Kafka topic including its configuration, partition count, and replication factor.
---

# kafka_topic (Data Source)

The `kafka_topic` data source retrieves information about an existing Kafka topic, including its partition count, replication factor, and configuration parameters. This is useful for referencing existing topics or validating topic configurations.

## Example Usage

### Basic Usage

```terraform
data "kafka_topic" "existing" {
  name = "application-events"
}

output "topic_partitions" {
  value = data.kafka_topic.existing.partitions
}

output "topic_replication" {
  value = data.kafka_topic.existing.replication_factor
}
```

### Referencing Topic Configuration

```terraform
data "kafka_topic" "logs" {
  name = "system-logs"
}

# Use the configuration in other resources
resource "kafka_topic" "logs_backup" {
  name               = "${data.kafka_topic.logs.name}-backup"
  partitions         = data.kafka_topic.logs.partitions
  replication_factor = data.kafka_topic.logs.replication_factor

  # Copy configuration from existing topic
  config = data.kafka_topic.logs.config
}
```

### Validation and Compliance

```terraform
data "kafka_topic" "production_topic" {
  name = "orders"
}

# Validate topic meets production standards
locals {
  topic_validation = {
    has_enough_replicas       = data.kafka_topic.production_topic.replication_factor >= 3
    has_min_insync_replicas   = lookup(data.kafka_topic.production_topic.config, "min.insync.replicas", "1") >= "2"
    has_appropriate_retention = lookup(data.kafka_topic.production_topic.config, "retention.ms", "0") >= "604800000" # 7 days
  }
}

output "topic_compliance" {
  value = alltrue(values(local.topic_validation)) ? "COMPLIANT" : "NON-COMPLIANT"
}
```

### Dynamic Resource Creation Based on Existing Topics

```terraform
# Get information about source topic
data "kafka_topic" "source" {
  name = var.source_topic_name
}

# Create mirror topic with same configuration
resource "kafka_topic" "mirror" {
  name               = "${var.source_topic_name}-mirror"
  partitions         = data.kafka_topic.source.partitions
  replication_factor = data.kafka_topic.source.replication_factor
  config             = data.kafka_topic.source.config
}

# Create consumer group ACLs based on topic
resource "kafka_acl" "consumer_group" {
  resource_name       = "${data.kafka_topic.source.name}-consumers"
  resource_type       = "Group"
  acl_principal       = "User:consumer-service"
  acl_host            = "*"
  acl_operation       = "Read"
  acl_permission_type = "Allow"
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `name` (String) The name of the topic.

### Read-Only

- `config` (Map of String) A map of string k/v attributes.
- `id` (String) The ID of this resource.
- `partitions` (Number) Number of partitions.
- `replication_factor` (Number) Number of replicas.

## Common Use Cases

### 1. Migration Planning

Use the data source to capture existing topic configurations before migrations:

```hcl
data "kafka_topic" "all_topics" {
  for_each = toset(var.topics_to_migrate)
  name     = each.key
}

resource "local_file" "migration_plan" {
  filename = "migration-plan.json"
  content = jsonencode({
    topics = {
      for name, topic in data.kafka_topic.all_topics : name => {
        partitions         = topic.partitions
        replication_factor = topic.replication_factor
        config            = topic.config
      }
    }
  })
}
```

### 2. Drift Detection

Compare actual topic configuration with expected:

```hcl
data "kafka_topic" "actual" {
  name = "important-topic"
}

locals {
  expected_config = {
    "retention.ms"        = "2592000000"  # 30 days
    "compression.type"    = "lz4"
    "min.insync.replicas" = "2"
  }
  
  config_drift = {
    for key, expected_value in local.expected_config :
    key => {
      expected = expected_value
      actual   = lookup(data.kafka_topic.actual.config, key, "NOT_SET")
      matches  = lookup(data.kafka_topic.actual.config, key, "") == expected_value
    }
  }
}

output "configuration_drift" {
  value = local.config_drift
}
```

### 3. Documentation Generation

```hcl
data "kafka_topic" "documented_topics" {
  for_each = toset(var.production_topics)
  name     = each.key
}

resource "local_file" "topic_documentation" {
  filename = "topic-documentation.md"
  content = templatefile("${path.module}/templates/topic-docs.tftpl", {
    topics = data.kafka_topic.documented_topics
  })
}
```

## Notes

- The data source requires read permissions on the Kafka cluster
- Topic configuration values are returned as strings, even for numeric values
- If a topic doesn't exist, the data source will fail
- Some configuration parameters may not be returned if they are set to defaults